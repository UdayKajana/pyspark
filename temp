import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions
from apache_beam.io.gcp.pubsub import ReadFromPubSub
import apache_beam.io.gcp.spanner as sp
import json
import argparse
import logging
from typing import NamedTuple, Iterator, Optional
from datetime import datetime, timezone
from apache_beam.transforms.trigger import AfterWatermark, AfterProcessingTime, AccumulationMode

class TemplateOptions(PipelineOptions):
    @classmethod
    def _add_argparse_args(cls, parser):
        parser.add_value_provider_argument('--params', type=str)

class ConvertToSpannerMutation(NamedTuple):
    telephone_number: Optional[str]
    trouble_report_number: Optional[str]
    address_id: Optional[str]
    chronic_flag: Optional[str]
    chronic_total: Optional[str]
    circuit_id: Optional[str]
    circuit_type: Optional[str]
    reported_ts: Optional[str]
    data_circuit_id: Optional[str]
    video_circuit_id: Optional[str]
    window_timestamp: Optional[str]
    insertion_timestamp: Optional[str]

beam.coders.registry.register_coder(ConvertToSpannerMutation, beam.coders.RowCoder)

class AttachArrivalTimestamp(beam.DoFn):
    def process(self, element):
        # Create timestamp in seconds with UTC timezone
        arrival_timestamp = datetime.now(timezone.utc).timestamp()
        
        if isinstance(element, beam.io.gcp.pubsub.PubsubMessage):
            timestamped_element = {
                'data': element.data,
                'attributes': element.attributes,
                'arrival_ts': arrival_timestamp
            }
        else:
            timestamped_element = {
                'data': element,
                'arrival_ts': arrival_timestamp
            }
        
        # Use the arrival timestamp for windowing
        yield beam.window.TimestampedValue(timestamped_element, arrival_timestamp)

# [Previous DecodeAvroRecords and PrepareSpannerData classes remain the same]

def run(known_args, beam_args):
    options = {
        'project': known_args.project,
        'runner': known_args.runner,
        'region': known_args.region,
        'staging_location': known_args.staging_location,
        'temp_location': known_args.temp_location,
        'template_location': known_args.template_location,
        'save_main_session': True,
        'streaming': True,
        'sdk_container_image': known_args.sdk_container_image,
        'sdk_location': 'container'
    }
    
    pipeline_options = PipelineOptions.from_dictionary(options)
    
    with beam.Pipeline(options=pipeline_options) as p:
        data = (p 
            | "Read From Pubsub" >> ReadFromPubSub(
                subscription=f"{known_args.pubsub_subscription_name}",
                with_attributes=True,
                timestamp_attribute=None  # Disable PubSub timestamp to use our custom timestamp
            )
            | "Attach Arrival Timestamp" >> beam.ParDo(AttachArrivalTimestamp())
            | "Window Into Fixed Intervals" >> beam.WindowInto(
                beam.window.FixedWindows(120),  # 2 minutes window
                trigger=AfterWatermark(
                    early=AfterProcessingTime(120),  # Fire early trigger after 120 seconds
                    late=beam.trigger.AfterCount(1)
                ),
                allowed_lateness=beam.transforms.window.Duration(seconds=300),
                accumulation_mode=AccumulationMode.ACCUMULATING
            )
            | "Decode Avro" >> beam.ParDo(DecodeAvroRecords())
            | 'Prepare Spanner Data' >> beam.ParDo(PrepareSpannerData())
        )

        _ = (data
            | "Write To Spanner" >> sp.SpannerInsertOrUpdate(
                instance_id=known_args.spanner_instance,
                database_id=known_args.spanner_dataset,
                project_id=known_args.spanner_project,
                table=known_args.spanner_table,
                expansion_service=known_args.expansion_service,
                max_number_mutations=7000,
                high_priority=True
            )
        )

# [Rest of the code remains the same]
